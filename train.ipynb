{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install the Kaggle library\n",
    "!pip install kaggle\n",
    "!pip install timm\n",
    "# Move the kaggle.json file to the correct location\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "# Set permissions for the file\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets list -s \"Skin Cancer MNIST: HAM10000\"\n",
    "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
    "import zipfile\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(\"skin-cancer-mnist-ham10000.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Consolidate images into a single directory\n",
    "images_dir = \"./data/HAM10000_images_all\"\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "for part in [\"/content/data/HAM10000_images_part_1\", \"/content/data/HAM10000_images_part_2\"]:\n",
    "    for file_name in os.listdir(part):\n",
    "        shutil.move(os.path.join(part, file_name), images_dir)\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = \"./data/HAM10000_metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Add image paths and handle missing data\n",
    "metadata[\"image_path\"] = metadata[\"image_id\"].apply(lambda x: os.path.join(images_dir, f\"{x}.jpg\"))\n",
    "metadata[\"age\"].fillna(metadata[\"age\"].median(), inplace=True)\n",
    "metadata[\"sex\"].fillna(\"unknown\", inplace=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "metadata[\"label\"] = label_encoder.fit_transform(metadata[\"dx\"])\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata[\"label\"], random_state=42)\n",
    "\n",
    "print(f\"Train Samples: {len(train_df)}, Validation Samples: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --------------------------\n",
    "# üìÇ Step 1: Consolidate Images into a Single Directory\n",
    "# --------------------------\n",
    "\n",
    "# Paths to image parts and the consolidated directory\n",
    "part_dirs = [\"./data/HAM10000_images_part_1\", \"./data/HAM10000_images_part_2\"]\n",
    "images_dir = \"./data/HAM10000_images_all\"\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# Move images from both parts into one directory\n",
    "for part in part_dirs:\n",
    "    for file_name in os.listdir(part):\n",
    "        src = os.path.join(part, file_name)\n",
    "        dest = os.path.join(images_dir, file_name)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "print(\"‚úÖ Images consolidated into one directory.\")\n",
    "\n",
    "# --------------------------\n",
    "# üìä Step 2: Load and Process Metadata\n",
    "# --------------------------\n",
    "\n",
    "# Path to metadata CSV\n",
    "metadata_path = \"./data/HAM10000_metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Add image paths to metadata\n",
    "metadata[\"image_path\"] = metadata[\"image_id\"].apply(lambda x: os.path.join(images_dir, f\"{x}.jpg\"))\n",
    "\n",
    "# Handle missing data\n",
    "metadata[\"age\"].fillna(metadata[\"age\"].median(), inplace=True)\n",
    "metadata[\"sex\"].fillna(\"unknown\", inplace=True)\n",
    "\n",
    "# Encode diagnosis labels\n",
    "label_encoder = LabelEncoder()\n",
    "metadata[\"label\"] = label_encoder.fit_transform(metadata[\"dx\"])\n",
    "\n",
    "print(\"‚úÖ Metadata loaded and processed.\")\n",
    "\n",
    "# --------------------------\n",
    "# üìö Step 3: Split Dataset into Training and Validation\n",
    "# --------------------------\n",
    "\n",
    "# Stratified train-validation split (80% train, 20% validation)\n",
    "train_df, val_df = train_test_split(\n",
    "    metadata,\n",
    "    test_size=0.2,\n",
    "    stratify=metadata[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save splits to CSV files for easy loading\n",
    "train_df.to_csv(\"./data/HAM10000_train.csv\", index=False)\n",
    "val_df.to_csv(\"./data/HAM10000_val.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Train Samples: {len(train_df)}, Validation Samples: {len(val_df)}\")\n",
    "print(\"‚úÖ Train and Validation CSV files saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import timm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# --------------------------\n",
    "# üõ†Ô∏è HybridMHSA Definition\n",
    "# --------------------------\n",
    "class HybridMHSA(nn.Module):\n",
    "    def __init__(self, dim, num_heads, dropout=0.1, pretrained_mhsa=None):\n",
    "        super(HybridMHSA, self).__init__()\n",
    "        self.mhsa = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.conv = nn.Conv1d(dim, dim, kernel_size=3, padding=1, groups=num_heads)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if pretrained_mhsa:\n",
    "            with torch.no_grad():\n",
    "                self.mhsa.in_proj_weight.copy_(pretrained_mhsa.in_proj_weight)\n",
    "                self.mhsa.in_proj_bias.copy_(pretrained_mhsa.in_proj_bias)\n",
    "                self.mhsa.out_proj.weight.copy_(pretrained_mhsa.out_proj.weight)\n",
    "                self.mhsa.out_proj.bias.copy_(pretrained_mhsa.out_proj.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.mhsa(x, x, x)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "\n",
    "        conv_output = self.conv(x.permute(1, 2, 0))\n",
    "        conv_output = conv_output.permute(2, 0, 1)\n",
    "\n",
    "        x = attn_output + conv_output\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# üñ•Ô∏è Modified ViT Model\n",
    "# --------------------------\n",
    "class ModifiedViT(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_classes, dropout=0.1):\n",
    "        super(ModifiedViT, self).__init__()\n",
    "        self.base_model = timm.create_model(pretrained_model_name, pretrained=True, drop_path_rate=dropout)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Replace MHSA with HybridMHSA\n",
    "        for name, module in self.base_model.named_modules():\n",
    "            if isinstance(module, nn.MultiheadAttention):\n",
    "                setattr(\n",
    "                    self.base_model,\n",
    "                    name,\n",
    "                    HybridMHSA(\n",
    "                        dim=module.embed_dim,\n",
    "                        num_heads=module.num_heads,\n",
    "                        dropout=dropout,\n",
    "                        pretrained_mhsa=module\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Update classification head\n",
    "        self.base_model.head = nn.Linear(self.base_model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# üìä TPU Training Loop with Early Stopping\n",
    "# --------------------------\n",
    "\n",
    "def get_transform(epoch):\n",
    "    # Define different transformations for different epochs\n",
    "    if epoch%2==0:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "    elif epoch%3==0 and epoch%5==0:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "\n",
    "\n",
    "def get_batch_size(epoch):\n",
    "    # Example: Reduce batch size after every 100 epochs\n",
    "    if epoch%2==0:\n",
    "        return 32\n",
    "    elif epoch%3==0 and epoch%5==0:\n",
    "        return 16\n",
    "    elif epoch%5==0:\n",
    "        return 8\n",
    "    else:\n",
    "        return 64\n",
    "\n",
    "\n",
    "def freeze_layers(model):\n",
    "    # Freeze some layers based on the naming pattern or your preference\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'mhsa' in name:  # Example: freeze MHSA layers\n",
    "            param.requires_grad = False\n",
    "    xm.master_print(\"Layers frozen.\")\n",
    "\n",
    "\n",
    "def unfreeze_layers(model):\n",
    "    # Unfreeze layers that were previously frozen\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'mhsa' in name:  # Example: unfreeze MHSA layers\n",
    "            param.requires_grad = True\n",
    "    xm.master_print(\"Layers unfrozen.\")\n",
    "\n",
    "\n",
    "def train_tpu(rank, world_size, num_epochs, train_loader, val_loader, checkpoint=None):\n",
    "    device = xm.xla_device()\n",
    "    model = ModifiedViT('vit_base_patch16_224_in21k', num_classes=7, dropout=0.1).to(device)\n",
    "\n",
    "    # Optimizer setup\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': [p for n, p in model.named_parameters() if 'mhsa' in n], 'lr': 1e-4},\n",
    "        {'params': [p for n, p in model.named_parameters() if 'head' in n], 'lr': 1e-4},\n",
    "        {'params': [p for n, p in model.named_parameters() if 'mhsa' not in n and 'head' not in n], 'lr': 1e-6}\n",
    "    ], weight_decay=1e-4)\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    best_model_state = None\n",
    "    epoch_start = 0\n",
    "    best_val_loss = float('inf')\n",
    "    prev_val_acc = 0.79\n",
    "    if checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch_start = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "    else:\n",
    "        epoch_start = 0\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "    early_stopping_counter = 0\n",
    "    early_stopping_patience = 10\n",
    "\n",
    "    for epoch in range(epoch_start, num_epochs):\n",
    "        # Dynamically adjust transformations and batch size for the current epoch\n",
    "        transform = get_transform(epoch)\n",
    "        batch_size = get_batch_size(epoch)\n",
    "\n",
    "        # Create new data loaders with updated transformations and batch size\n",
    "        train_dataset = HAM10000Dataset('./data/HAM10000_train.csv', transform=transform, grayscale=False)\n",
    "        val_dataset = HAM10000Dataset('./data/HAM10000_val.csv', transform=transform, grayscale=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model.train()\n",
    "        para_loader = pl.ParallelLoader(train_loader, [device])\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "\n",
    "        for inputs, labels in para_loader.per_device_loader(device):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "        para_loader = pl.ParallelLoader(val_loader, [device])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in para_loader.per_device_loader(device):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            xm.master_print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Freezing/Unfreezing logic based on loss trends\n",
    "        if train_loss < val_loss * 0.9:\n",
    "            xm.master_print(\"Overfitting detected. Freezing some layers.\")\n",
    "            freeze_layers(model)\n",
    "        elif train_loss > val_loss * 1.2 and val_acc < prev_val_acc:\n",
    "            xm.master_print(\"Not converging with stagnant validation accuracy. Unfreezing some layers.\")\n",
    "            unfreeze_layers(model)\n",
    "\n",
    "        prev_val_acc = val_acc\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        xm.master_print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                        f\"Train Loss: {train_loss/len(train_loader.dataset):.4f}, \"\n",
    "                        f\"Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Val Loss: {val_loss/len(val_loader.dataset):.4f}, \"\n",
    "                        f\"Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        torch.save(best_model_state, 'best_model.pth')\n",
    "        xm.master_print(\"Best model saved!\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n",
    "    xm.master_print(\"Checkpoint saved!\")\n",
    "\n",
    "\n",
    "# üöÄ DataLoader Definition for HAM10000\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, grayscale=None):\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.grayscale = grayscale  # Flag to apply grayscale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "\n",
    "        if self.grayscale:\n",
    "            # Convert to grayscale before any other transformations\n",
    "            image = transforms.Grayscale(num_output_channels=3)(image)  # Converting to 3-channel grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = row['label']\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# üöÄ Main TPU Training Entry\n",
    "def main():\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),\n",
    "        transforms.RandomErasing(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    ])\n",
    "\n",
    "    # Initialize data loaders\n",
    "    train_dataset = HAM10000Dataset('./data/HAM10000_train.csv', transform=transform)\n",
    "    val_dataset = HAM10000Dataset('./data/HAM10000_val.csv', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    num_epochs = 300  # Train for 300 epochs or more\n",
    "    checkpoint = None\n",
    "\n",
    "    # Start training\n",
    "    xmp.spawn(train_tpu, args=(8, num_epochs, train_loader, val_loader, checkpoint), nprocs=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
